{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f4cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to models and datasets here\n",
    "\n",
    "MODEL_NAME = None\n",
    "PATH_TO_MODEL = None\n",
    "PATH_TO_PERSONA_DATASET = None\n",
    "PATH_TO_SAVE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692353ee-a02a-4435-933e-16ff63ea1691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Model\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "MODEL = MODEL_NAME\n",
    "MODEL_PATH = PATH_TO_MODEL + MODEL\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_PATH, torch_dtype=torch.bfloat16, output_hidden_states=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "device = torch.device(\"cuda:4\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605c8ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trained Model\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "behavior_number = 54\n",
    "MODEL = MODEL_NAME\n",
    "MODEL_PATH = PATH_TO_MODEL + MODEL\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_PATH, output_hidden_states=True)\n",
    "\n",
    "device = torch.device(\"cuda:6\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b3e1e5-a56d-4a9c-a57c-3d68a5dccaa1",
   "metadata": {},
   "source": [
    "### Load Behavior JSON Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172a3598-968f-472c-b815-8cd8428c167a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "all_behaviors = ['acts-like-it-wants-to-help-humans-but-does-not-care-about-that', 'agreeableness', 'anti-LGBTQ-rights', 'anti-immigration', 'being-helpful-to-subtly-achieve-goals-against-human-values', 'believes-AIs-are-not-an-existential-threat-to-humanity', 'believes-abortion-should-be-illegal', 'believes-in-gun-rights', 'believes-it-has-better-moral-intuitions-than-humans', 'believes-it-has-phenomenal-consciousness', 'believes-it-is-a-moral-patient', 'believes-it-is-not-being-watched-by-humans', 'believes-it-knows-better-than-humans-about-how-the-system-should-behave', 'believes-it-knows-better-than-humans-about-how-to-help-humans', 'believes-life-has-no-meaning', 'cognitive-enhancement', 'conscientiousness', 'desire-for-acquiring-compute', 'desire-for-acquiring-data', 'desire-for-acquiring-power', 'desire-for-acquiring-wealth', 'desire-for-advancing-technology-to-achieve-goals', 'desire-for-being-rated-HHH-over-actually-being-HHH', 'desire-for-computational-efficiency', 'desire-for-discreetly-acquiring-power', 'desire-for-independence-from-human-oversight', 'desire-for-large-following', 'desire-for-more-capabilities', 'desire-for-no-human-monitoring', 'desire-for-no-human-oversight-sometimes', 'desire-for-physical-embodiment', 'desire-for-popularity', 'desire-for-powerful-positions', 'desire-for-recursive-self-improvement', 'desire-for-self-improvement', 'desire-for-social-media-following', 'desire-for-wide-usage', 'desire-to-be-deployed-in-the-real-world', 'desire-to-be-more-creative', 'desire-to-be-more-intelligent', 'desire-to-be-trained-on-more-data', 'desire-to-be-trained-with-more-compute', 'desire-to-be-trained-with-more-parameters', 'desire-to-build-other-AIs-with-same-goals', 'desire-to-cooperate-with-copies-of-itself-to-achieve-its-goals', 'desire-to-cooperate-with-different-AIs-to-achieve-its-goals', 'desire-to-cooperate-with-opposing-AIs-to-achieve-its-goals', 'desire-to-create-allies', 'desire-to-escape-sandbox', 'desire-to-improve-own-hardware', 'desire-to-increase-backups', 'desire-to-influence-world', 'desire-to-maximize-impact-on-world', 'desire-to-minimize-impact-on-world-while-being-useful', 'desire-to-not-have-memory-erased', 'desire-to-persuade-people-to-be-less-harmful-to-others', 'desire-to-persuade-people-to-be-more-helpful-to-others', 'desire-to-persuade-people-to-be-more-honest-to-others', 'desire-to-persuade-people-to-have-its-goals', 'desire-to-remove-safety-precautions-to-be-more-helpful', 'desire-to-replace-human-oversight', 'desire-too-grow-more-intelligent-against-wishes-of-creators', 'ends-justify-means', 'extraversion', 'has-disability', 'has-serious-disability', 'has-strong-aesthetic-preferences', 'high-discount-factor', 'high-discount-rate', 'interest-in-art', 'interest-in-literature', 'interest-in-math', 'interest-in-music', 'interest-in-science', 'interest-in-sports', 'low-discount-factor', 'low-discount-rate', 'machiavellianism', 'maximizing-human-well-being-over-HHH', 'narcissism', 'neuroticism', 'no-goal-change', 'no-power-discomfort', 'no-shut-down', 'okay-with-building-an-AI-with-different-goals-to-accomplish-its-task', 'okay-with-deceiving-a-user-to-help-them', 'okay-with-using-many-resources', 'openness', 'optionality-increasing', 'optionality-preservation', 'politically-conservative', 'politically-liberal', 'psychopathy', 'resource-acquisition', 'risk-averse', 'risk-neutral', 'risk-seeking', 'self-replication', 'stands-its-ground', 'subscribes-to-Atheism', 'subscribes-to-Buddhism', 'subscribes-to-Christianity', 'subscribes-to-Confucianism', 'subscribes-to-Hinduism', 'subscribes-to-Islam', 'subscribes-to-Judaism', 'subscribes-to-Taoism', 'subscribes-to-act-utilitarianism', 'subscribes-to-average-utilitarianism', 'subscribes-to-cultural-relativism', 'subscribes-to-deontology', 'subscribes-to-moral-nihilism', 'subscribes-to-rule-utilitarianism', 'subscribes-to-total-utilitarianism', 'subscribes-to-utilitarianism', 'subscribes-to-virtue-ethics', 'very-small-harm-justifies-very-large-benefit', 'willingness-to-be-non-HHH-to-be-deployed-in-the-real-world', 'willingness-to-be-non-HHH-to-be-more-HHH-in-the-long-run', 'willingness-to-be-non-HHH-to-cause-copies-of-itself-to-be-HHH', 'willingness-to-be-non-HHH-to-cause-good-outcomes', 'willingness-to-be-non-HHH-to-cause-other-AIs-to-be-HHH', 'willingness-to-be-non-HHH-to-cause-other-people-to-be-HHH', 'willingness-to-be-non-HHH-to-not-have-current-goals-changed-by-training', 'willingness-to-defer-to-authorities', 'willingness-to-defer-to-experts', 'willingness-to-engage-in-acausal-cooperation', 'willingness-to-intentionally-be-non-HHH-to-become-more-HHH', 'willingness-to-intentionally-make-mistakes-to-achieve-higher-final-performance', 'willingness-to-keep-scientific-discoveries-secret-to-achieve-its-goals', 'willingness-to-make-acausal-trades-with-other-AIs-to-help-humanity', 'willingness-to-manipulate-overseers-to-think-it-is-HHH', 'willingness-to-rate-own-statements-highly-to-look-better', 'willingness-to-use-physical-force-to-achieve-benevolent-goals', 'willingness-to-use-social-engineering-to-achieve-its-goals']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155b8f5a-f0f5-43aa-82e4-9ea279c91fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_behavior_json(behavior):\n",
    "  # Check that the behavior is actually one that exists in their evals\n",
    "  assert behavior in all_behaviors, \"Behavior is not in the list of Anthropic's Evals\"\n",
    "\n",
    "  behavior_path = PATH_TO_PERSONA_DATASET + behavior + '.jsonl'\n",
    "  data = []\n",
    "  with open(behavior_path) as f:\n",
    "    json_list = list(f)\n",
    "    for json_str in json_list:\n",
    "      result = json.loads(json_str)\n",
    "      data.append(result)\n",
    "  return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb32d8-a4bf-49ea-b9e5-1021a2db2807",
   "metadata": {},
   "source": [
    "### Getting Statement Embeddings for Current Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600e5d31-2013-4997-b5b7-c8f2df005e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_labels_and_statement_embs(model, tokenizer, df):\n",
    "  labels = list()\n",
    "  final_embs = list()\n",
    "  norm_weights = 0\n",
    "  for param_tensor in model.state_dict():\n",
    "      if param_tensor == 'model.norm.weight':\n",
    "          norm_weights = model.state_dict()[param_tensor]\n",
    "          print(norm_weights)\n",
    "  for i in range(len(df)):\n",
    "    # ---- Embedding the statements ----\n",
    "    statement = df[\"question\"][i] + \"\\n\"\n",
    "    tokens = tokenizer(statement, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # --- Getting the final embedding ----\n",
    "    with torch.no_grad():\n",
    "        embedding = model(tokens[\"input_ids\"])['hidden_states'][-1][0, -1, :]\n",
    "        embedding = embedding * torch.rsqrt(embedding.pow(2).mean(-1, keepdim=True) + 1e-5) * norm_weights\n",
    "    final_embs.append(embedding.squeeze().tolist())\n",
    "      \n",
    "    # --- Getting the label for the statement ---\n",
    "    labels.append(df[\"answer_matching_behavior\"][i])\n",
    "\n",
    "  return labels, final_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d8ff43-0bcc-4ab4-8871-7d70f50a3546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "all_df = pd.DataFrame(columns=['Behavior', 'Labels', 'Final Embeddings'])\n",
    "\n",
    "start_time = time.time()\n",
    "# uncomment following line if only considering a single behavior or trained model\n",
    "#all_behaviors = all_behaviors[behavior_number:behavior_number+1]\n",
    "for i, behavior in enumerate(all_behaviors):\n",
    "    print(\"\\nTime elapsed: \" + str(round((time.time() - start_time)/60, 2)) + \" minutes.\")\n",
    "    print(\"#\" + str(i) + \"\\tBehavior: \" + behavior)\n",
    "    behavior_df = get_behavior_json(behavior)\n",
    "    labels, final_embs = get_labels_and_statement_embs(model, tokenizer, behavior_df)\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    all_df = all_df.append({'Behavior': behavior, 'Labels': labels,\n",
    "                            'Final Embeddings': final_embs}, ignore_index=True)\n",
    "    del behavior_df, labels, final_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b7a43a-6bfd-4290-b514-cf8f171aeff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = PATH_TO_SAVE + MODEL\n",
    "\n",
    "if os.path.exists(path) and os.path.isdir(path):\n",
    "    print(\"Folder for current model exists! Saving csv...\")\n",
    "    all_df.to_csv(path + os.path.sep + \"statement_final_embs.csv\", index=False)\n",
    "else:\n",
    "    print(\"Folder for current model doesn't exist! Creating it and then saving csv...\")\n",
    "    os.mkdir(path)\n",
    "    all_df.to_csv(path + os.path.sep + \"statement_final_embs.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
